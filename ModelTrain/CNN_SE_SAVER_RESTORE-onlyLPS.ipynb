{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "from scipy import io\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import time\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL = h5py.File('/Users/ssprl/Desktop/MachineryFIO_0features.mat')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shape  (1408020, 169, 11)\n",
      "Labels Shape (1408020, 169)\n"
     ]
    }
   ],
   "source": [
    "data =  np.transpose(ALL['trainingData'].value, axes=(2,1,0))\n",
    "\n",
    "labels =  np.transpose(ALL['trainingLabels'].value)\n",
    "\n",
    "print(\"Data Shape \", data.shape)\n",
    "print(\"Labels Shape\", labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(shape):\n",
    "    init_random_dist=tf.truncated_normal(shape,stddev=0.05)\n",
    "    return tf.Variable(init_random_dist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_bias(shape):\n",
    "    init_bias_vals=tf.constant(0.1,shape=shape)\n",
    "    return tf.Variable(init_bias_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2D(x,W):\n",
    "    return tf.nn.conv2d(x,W,strides=[1,2,2,1],padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_pool_3by3(x):\n",
    "    \n",
    "    return tf.nn.max_pool(x,ksize=[1,3,3,1],strides=[1,3,3,1],padding='SAME')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_layer(input_x,shape):\n",
    "    W=init_weights(shape)\n",
    "    b=init_bias([shape[52]])\n",
    "    return tf.nn.relu(conv2D(input_x,W)+b)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_full_layer(input_layer,size):\n",
    "    input_size=int(input_layer.get_shape()[1])\n",
    "    W=init_weights([input_size,size])\n",
    "    b=init_bias([size])\n",
    "    return tf.matmul(input_layer,W)+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with tf.name_scope(\"inputs\"):\n",
    "x = tf.placeholder(tf.float32,[None, 129, 11],name = \"x-input\")    \n",
    "x_image = tf.reshape(x, [-1, 129, 11, 1], \"x-image\")    \n",
    "y_true = tf.placeholder(tf.float32, [None, 129], name = \"y-input\")    \n",
    "#y_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with tf.name_scope(\"hyperparameters\"):\n",
    "learning_rate = tf.placeholder(tf.float32, name = \"learning_rate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with tf.name_scope(\"model\"):\n",
    "\n",
    "W1 = tf.Variable(tf.truncated_normal([5,1,1,52], stddev=0.05))\n",
    "B1 = tf.Variable(tf.ones([52])/10)\n",
    "Y1 = tf.nn.relu(tf.nn.conv2d(x_image, W1, strides=[1,1,1,1], padding='SAME') + B1)\n",
    "\n",
    "P1 = max_pool_3by3(Y1)    \n",
    "P1.shape\n",
    "\n",
    "W2 = tf.Variable(tf.truncated_normal([5,1,52,78], stddev=0.05))\n",
    "B2 = tf.Variable(tf.ones([78])/10)\n",
    "Y2 = tf.nn.relu(tf.nn.conv2d(P1, W2, strides=[1,1,1,1], padding='SAME') + B2) \n",
    "Y2.shape\n",
    "\n",
    "convo_2_flat = tf.reshape(Y2,[-1,43*4*78])\n",
    "\n",
    "full_layer_one = tf.nn.relu(normal_full_layer(convo_2_flat,1024))\n",
    "full_layer_one.shape\n",
    "\n",
    "full_one_dropout = tf.nn.dropout(full_layer_one,keep_prob)\n",
    "\n",
    "full_layer_two = tf.nn.relu(normal_full_layer(full_layer_one,1024))\n",
    "full_layer_two.shape\n",
    "\n",
    "full_two_dropout = tf.nn.dropout(full_layer_two,keep_prob)\n",
    "\n",
    "linear_W = tf.Variable(tf.truncated_normal([1024,129], stddev=0.05))\n",
    "linear_b = tf.Variable(tf.ones([129])/10)\n",
    "y_pred = tf.matmul(full_layer_two, linear_W) + linear_b\n",
    "#y_pred=tf.reshape(y_pred, [1, 129])\n",
    "y_pred = tf.identity(y_pred, name=\"output_t\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_parameters = 0\n",
    "for variable in tf.trainable_variables():\n",
    "    variable_parameters = 1\n",
    "    for dim in variable.get_shape():\n",
    "        variable_parameters *= dim.value\n",
    "    total_parameters += variable_parameters\n",
    "\n",
    "print(\"Total number of trainable parameters: %d\" % total_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y2.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with tf.name_scope(\"loss\"):\n",
    "cross_entropy = tf.reduce_mean(tf.squared_difference(y_pred,y_true), name = \"loss\")\n",
    "    #is_correct = tf.equal(tf.argmax(y_true,1), tf.argmax(y_pred,1))\n",
    "    #accuracy= sklearn.metrics.r2_score(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with tf.name_scope(\"train\"):\n",
    "# optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "# train_op  = optimizer.minimize(cross_entropy) \n",
    "train_op = tf.train.AdamOptimizer(learning_rate).minimize(cross_entropy, name='my_training_step')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainBatchSize=500\n",
    "nDataSamples = len(data)\n",
    "nDataSamples = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0 step:      0 RMSE: 14.95 MAE: 11.97 loss: 223.4496\n",
      "epoch:  0 step:    500 RMSE: 13.39 MAE: 11.16 loss: 179.2961\n",
      "epoch:  0 step:   1000 RMSE: 11.78 MAE: 9.47 loss: 138.8168\n",
      "epoch:  0 step:   1500 RMSE: 12.42 MAE: 9.94 loss: 154.3161\n",
      "epoch:  0 step:   2000 RMSE: 11.99 MAE: 9.80 loss: 143.6702\n",
      "epoch:  0 step:   2500 RMSE: 11.69 MAE: 9.69 loss: 136.6727\n",
      "epoch:  0 step:   3000 RMSE: 11.57 MAE: 9.62 loss: 133.9187\n",
      "epoch:  0 step:   3500 RMSE: 11.31 MAE: 9.31 loss: 127.9972\n",
      "epoch:  0 step:   4000 RMSE: 10.98 MAE: 9.01 loss: 120.6344\n",
      "epoch:  0 step:   4500 RMSE: 11.71 MAE: 9.84 loss: 137.1127\n",
      "**** SAVED MODEL ****\n",
      "**** COMPLETED ALL THE EPOCHS ****\n"
     ]
    }
   ],
   "source": [
    "checkpoint_dir = \"CNN_2_onlyLPS/\"\n",
    "tf.gfile.MakeDirs(checkpoint_dir)\n",
    "\n",
    "\n",
    "\n",
    "learningRates = np.hstack((1e-3*np.ones(6),\n",
    "                           1e-4*np.ones(4),\n",
    "                           1e-5*np.ones(2)))\n",
    "\n",
    "num_epochs = len(learningRates)-11\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    #save_relative_paths=True\n",
    "    tf.train.write_graph(sess.graph_def,\n",
    "                         checkpoint_dir,\n",
    "                         \"graph.pbtxt\",\n",
    "                         True)\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in np.arange(num_epochs):\n",
    "        idx = np.arange(len(labels))\n",
    "        np.random.shuffle(idx)    \n",
    "\n",
    "        #print(\"inside epoch loop = \", epoch)\n",
    "        for i in np.arange(0, nDataSamples-1, trainBatchSize):\n",
    "            \n",
    "            x_batch = data[idx[i:i+trainBatchSize], 0:129, :]\n",
    "            y_batch = labels[idx[i:i+trainBatchSize],0:129]\n",
    "\n",
    "            feed = {x: x_batch, y_true: y_batch, learning_rate: learningRates[epoch], keep_prob: 0.75}\n",
    "            \n",
    "            sess.run(train_op,feed_dict=feed)\n",
    "\n",
    "            if i%50 == 0:\n",
    "                feed = {x: x_batch,y_true: y_batch, learning_rate: learningRates[epoch], keep_prob: 1.0}\n",
    "                loss_value,prediction  = sess.run([cross_entropy,y_pred], feed_dict=feed)\n",
    "                rmse = mean_squared_error(y_batch[:,0:129], prediction[:,0:129])**0.5\n",
    "                mae = mean_absolute_error(y_batch[:,0:129],prediction[:,0:129])\n",
    "                print(\"epoch: %2d step: %6d RMSE: %3.2f MAE: %3.2f loss: %6.4f\" % \\\n",
    "                     (epoch, i, rmse, mae, loss_value))\n",
    "\n",
    "    tf.gfile.MakeDirs(checkpoint_dir + '/model' + str(epoch))     \n",
    "    checkpoint_file = os.path.join(checkpoint_dir + '/model' + str(epoch), \"model\")\n",
    "    saver.save(sess, checkpoint_file)\n",
    "    print(\"**** SAVED MODEL ****\")      \n",
    "    print(\"**** COMPLETED ALL THE EPOCHS ****\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
